# RAG система для банковской информации

Демонстрационный проект для реализации Retrieval Augmented Generation (RAG) с использованием современных инструментов и подходов.

## Основные компоненты

- **Векторное хранилище**: FAISS для эффективного поиска похожих документов
- **Модели эмбеддингов**: deepvk/USER-bge-m3
- **Ранжировщик**: BAAI/bge-reranker-v2-m3 для уточнения релевантности результатов
- **LLM**: Доступ к различным моделям через OpenRouter API (Gemini, Llama, Claude и т.д.)
- **Оценка качества**: Реализация RAG Triad метрик (Faithfulness, Answer Relevancy, Contextual Relevancy)

## Структура проекта

- `core/` - основные компоненты системы
  - `db/` - работа с векторным хранилищем
  - `llm/` - работа с языковыми моделями
  - `modules/` - вспомогательные модули для обработки данных
  - `utils/` - утилиты, синглтоны и т.д.
- `data/` - данные для индексации и результаты
- `evals/` - код для оценки качества генерации
- `scripts/` - скрипты для запуска различных задач
- `app.py` - демонстрационное веб-приложение на Streamlit

## Особенности реализации

- Использование паттерна синглтон для эффективного управления ресурсами
- Асинхронная оценка нескольких LLM моделей
- Настраиваемые компоненты (можно заменить эмбеддер, ранжировщик, и т.д.)
- Интеграция с библиотекой DeepEval для оценки качества RAG-системы

# Запуск на TPU

Для запуска скрипта оценки моделей на TPU (v3-v8) выполните следующие шаги:

## 1. Установка зависимостей для TPU

```bash
pip install -r requirements.txt
```

## 2. Настройка окружения для TPU

Для Google Cloud TPU:

```bash
export XRT_TPU_CONFIG="localservice;0;localhost:51011"
```

## 3. Запуск скрипта на TPU

```bash
python scripts/evaluate_models.py
```

Скрипт автоматически определит наличие TPU и будет использовать его для вычислений.

## Примечания по работе с TPU

- Скрипт оптимизирован для работы как с TPU, так и с GPU/CPU
- При работе на TPU используется библиотека `torch_xla` для оптимизации вычислений
- Для больших моделей рекомендуется использовать TPU v4-8 или выше
- При использовании TPU Pod необходимо настроить распределенные вычисления через `xmp.spawn` 